# 利用不确定性感知图网络在航空图像中进行目标检测

**Jongha Kim**, **Korea University**

## 摘要

在这项工作中，我们提出了一个具有结构图的高度不确定性感知对象保护框架，其中节点和边分别表示对象及其空间语义相似性。具体来说，我们的目标是考虑对象之间的关系，以便有效地将其上下文关联起来。为此，我们首先检测对象，然后测量它们的语义和空间距离，构建对象图，然后用图神经网络（GNN）表示，以完善对象的视觉 CNN 特征。然而，提炼每个物体的 CNN 特征和检测结果的效率很低，而且可能没有必要，因为这包括低不确定性的正确预测。因此，我们建议处理不确定的物体，不仅要在有向图上将特定物体（来源）的表征转移到不确定的物体（目标）上，还要仅在被视为不确定的物体上利用 GNN 的表征输出改进 CNN 特征。此外，我们通过对不确定对象赋予较大权重来计算训练损失，以便在保持对某些对象的高性能的同时，集中精力改进不确定对象的预测。我们将这一模型称为对象检测的不确定性感知图网络（UAGDet）。然后，我们在具有挑战性的大规模航空图像数据集（即 DOTA）上对我们的模型进行了实验验证，该数据集由图像中大量大小不一的物体组成，在该数据集上，我们的模型提高了现有物体检测网络的性能。

**关键词**： 目标检测， 图神经网络， 不确定性

## 导言

给定一幅输入图像，物体检测的目标是找到图像中感兴趣物体的边界框及其相应类别。为了完成这一任务，人们提出了各种基于传统卷积神经网络（CNN）的物体检测模型，包括 Faster R-CNN 和 YOLO，以及最近提出的基于Transformer的模型，如DETR和 Deformable DETR，这些模型都表现出了不俗的性能。换句话说，人们一直非常关注寻找新的架构，以提高它们在各种物体检测任务中的性能，例如，从Earth Vision中的航空图像中寻找物体。

# 利用不确定性感知图网络在航空图像中进行目标检测

**Jongha Kim**, **Korea University**

## 摘要

在这项工作中，我们提出了一个具有结构图的高度不确定性感知对象保护框架，其中节点和边分别表示对象及其空间语义相似性。具体来说，我们的目标是考虑对象之间的关系，以便有效地将其上下文关联起来。为此，我们首先检测对象，然后测量它们的语义和空间距离，构建对象图，然后用图神经网络（GNN）表示，以完善对象的视觉 CNN 特征。然而，提炼每个物体的 CNN 特征和检测结果的效率很低，而且可能没有必要，因为这包括低不确定性的正确预测。因此，我们建议处理不确定的物体，不仅要在有向图上将特定物体（来源）的表征转移到不确定的物体（目标）上，还要仅在被视为不确定的物体上利用 GNN 的表征输出改进 CNN 特征。此外，我们通过对不确定对象赋予较大权重来计算训练损失，以便在保持对某些对象的高性能的同时，集中精力改进不确定对象的预测。我们将这一模型称为对象检测的不确定性感知图网络（UAGDet）。然后，我们在具有挑战性的大规模航空图像数据集（即 DOTA）上对我们的模型进行了实验验证，该数据集由图像中大量大小不一的物体组成，在该数据集上，我们的模型提高了现有物体检测网络的性能。

**关键词**： 目标检测， 图神经网络， 不确定性

## 导言

给定一幅输入图像，物体检测的目标是找到图像中感兴趣物体的边界框及其相应类别。为了完成这一任务，人们提出了各种基于传统卷积神经网络（CNN）的物体检测模型，包括 Faster R-CNN [29] 和 YOLO [28]，以及最近提出的基于变换器 [32] 的模型，如 DETR [3] 和 Deformable DETR [37]，这些模型都表现出了不俗的性能。换句话说，人们一直非常关注寻找新的架构，以提高它们在各种物体检测任务中的性能，例如，从地球视觉[34]中的航空图像中寻找物体。

图 1：概念图。给定一幅输入图像，进行初始对象检测，同时产生对象的不确定性。不确定性低的蓝色物体和不确定性高的红色物体分别被设定为源节点和目标节点。连接源节点和目标节点的有向图（图边根据节点之间的空间语义距离生成）被输入到 GNN，以获得对象的精细表示。

然而，尽管这些模型取得了巨大成功，但大多数现有模型都存在局限性，因为它们没有明确考虑物体之间的相互作用，这与人类感知图像的方式不同：考虑每个物体与其他物体在空间和语义上的关系，以及捕捉局部区域的视觉特征，从而将给定图像的上下文关联起来。因此，我们认为，对于任何物体检测网络来说，建立图像中物体间明确关系模型的方案都是必要的。需要注意的是，与传统数据集（即 COCO [26] 或 Pascal VOC [9]）中的图像相比，在处理我们主要针对的航空图像 [34] 时，这一点变得更加重要。考虑图像中的关系最直接的方法是构建一个固有的层次结构，其中用于识别局部的局部级特征由 CNN 对子区域的输出获得，而用于整体理解整幅图像的全局级特征则由汇总局部获得的 CNN 特征获得[27,25,5]。然而，这种方案非常不理想，因为它没有明确考虑对象表征的对象之间的语义和空间关系，但却用不同子区域的 CNN 特征隐含地模拟了它们之间的关系。因此，在这项工作中，我们的目标是首先用传统的物体检测网络（如 Faster R-CNN [29] 或 RoITransformer [7]）检测给定输入图像中的物体，然后用它们的语义和空间特征距离计算它们之间的边缘。然后，在以对象为节点、以它们之间的距离为边的构建图上，我们利用图神经网络（GNN）[23,17] 获得对象的图形特征，然后将这些特征与之前获得的视觉 CNN 特征相结合，以提高最终的对象预测性能。需要注意的是，最近也有一些类似的工作[20,35]，通过构建全连接对象图[20]或空间感知稀疏图[35]来考虑所有对象之间的显式交互，其对象表示被用于改进对象检测的 CNN 特征。然而，是否有必要完善每个物体的 CNN 特征和检测结果呢？

我们认为，如果物体检测网络的预测结果足够确定，就没有必要更换其特征和预判词标签。因此，在这项工作中，我们的目标是在构建对象图和完善给定图像中的对象特征时，利用每个对象的不确定性，仅对检测模型大多感到困惑的不确定对象改进预测结果。具体来说，当我们构建一个由物体（节点）及其语义和空间相似性（边）组成的图时，我们建议通过在有向图表示的边上定义方向，将信息从确定的物体传播到不确定的物体。与考虑所有对象对的现有模型[20,35]相比，由于忽略了特定对象之间的大量边，这种方案不仅能使模型通过与语义和空间相关的特定对象的上下文关系来改进不确定对象的特征，还能防止特定对象接收来自不确定对象的噪声信息，因此具有很高的效率。此外，当我们根据 GNN 中对象图的代表来完善 CNN 特征时，我们建议只对不确定对象的特征进行操作，而不是改变所有对象的特征，这使得模型能够在保持对某些对象的高预测性能的同时，专注于改进不确定对象。最后，为了进一步使模型专注于不确定的对象，我们根据不确定性对训练损失进行了缩放，不确定的预测在损失中获得了更高的权重。
我们将这种新颖的对象检测框架称为对象检测的不确定性感知图网络（Uncertainty-Aware Graph network for object DETection，UAGDet），如图 1 所示。然后，我们在大型航空图像物体检测数据集（DOTA）[34] 的两个不同版本上对 UAGDet 进行了实验验证： DOTA-v1.0 和 DOTA-v1.5，其中包含大量小型不确定物体，且这些物体之间存在充分的交互。因此，我们认为我们的 UAGDet 能够在这种具有挑战性的场景中发挥巨大作用。实验中，我们使用 RoITrans [7] 作为骨干对象检测网络，结果表明，在 DOTA-v1.0 和 -v1.5 数据集上，以平均精度（mAP）作为评估指标，我们的 UAGDet 与 RoITrans 骨干网络相比，性能分别提高了 2.32% 和 3.82%。此外，进一步的分析表明，我们的图构建方法同时考虑了语义和空间特征，通过边将相关对象连接起来，而且错误预测的不确定性也很高，而图表示法中的精炼特征可以纠正这些不确定性。

## 相关工作

**物体检测**。物体检测是指在图像中定位和分类感兴趣对象的任务。仅举几例，Faster R-CNN [29] 和 YOLO [28] 是基于两个早期的CNN模型，成功展示了深度学习在物体检测任务中的能力。最近，继自然语言处理中transformers [32]的成功之后，DETR [3] 在物体检测任务中采用了transformers，它对输入图像不同子区域的CNN特征执行自我关注，以考虑它们之间的关系。此外，提出了Deformable DETR [37]，它在执行自我关注时仅关注相对空间位置，而不是考虑所有位置，这使得基于transformer的预测架构更加高效。然而，尽管它们在开发新的物体检测网络及其性能方面取得了巨大进步，但它们在很大程度上忽略了对象之间的关系。特别是，基于CNN的模型依赖于构建局部和全局特征的层次结构，通过多级特征图来捕捉特征层面的关系，这被称为特征金字塔网络（FPN）[25]，但没有捕捉显式的对象级关系。同时，基于transformer的模型只隐式地考虑对象的候选查询之间的关系，但候选查询通常包括重复的对象或无意义的背景区域，这些特别属于“无对象”。因此，与这些先前的工作不同，我们提出明确地对对象级关系进行建模，通过最初检测对象，然后在以对象为节点的图结构上，用图神经网络（GNNs）表示它们，以获得图形特征，然后将这些特征与CNN特征结合，用于最终的物体检测。

**用于物体检测的图神经网络**。图神经网络（GNNs）通过从目标节点的邻居处迭代聚合特征，表现出对由节点和边组成的图结构数据的表达能力，近年来受到了广泛关注，在处理图数据的各种下游任务中取得了成功[23,16,33,2,21,17]。由于这种模型架构在表示它们时明确利用了连接实例之间的关系，因此最近有尝试在物体检测任务中使用GNNs来捕获对象之间的交互[35,24,4]。例如，GAR [24] 构建了一个考虑对象和场景之间交互的上下文图，但也考虑了对象之间的交互，通过形成对象和场景作为节点以及它们的连接作为边，然后用GNNs表示这个图。类似地，Relation R-CNN [4] 使用预先构建的共现矩阵和对象之间的距离分别生成语义和空间关系网络，对象作为节点，用于形成边。然而，GAR [24] 和 Relation R-CNN [4] 都有一个明显的局限性，即边生成过程不是端到端可训练的，而是基于使用预先计算的实例间共现统计的简单启发式。另一方面，SGRN [35] 学习了基于视觉特征和初始提议的空间距离的对象间空间感知关系网络，然后转发给GNNs以获取对象的表示。值得注意的是，我们的工作与这些相关工作有关键区别：我们不是处理所有对象提议，而是首先通过非最大抑制（NMS）[6,10]大幅减少它们，然后旨在通过从确定对象到不确定对象生成语义和空间方向的边，提高模型对大量混淆的不确定对象的改进，这在处理单个图像中的许多对象时（例如，DOTA [34]）大大减少了计算成本。

**不确定性感知物体检测**。在计算机视觉任务中，贝叶斯深度学习的重点之一是准确捕捉模型预测的不确定性，从而使深度学习模型在不确定性较高时不会做出错误的预测。随着不确定性在语义分割和深度估计任务中的成功应用[11,22,30]，一些研究提出在物体检测任务中也利用不确定性[19,13]。其中，Xu 等人[19] 提出，在执行软 NMS[1] 时，根据从不确定性中获得的坐标权重（即不确定性越大，权重越低）合并重叠的边界框，这有助于准确定位边界框。此外，CertainNet [13] 使用预测特征与可学习类中心点之间的距离来衡量不确定性（即推理时距离越大，不确定性越高），它基于确定性不确定性量化（DUQ）[31] 的工作。不过，它并不利用不确定性来改进模型的预测，而只是计算预测对象的不确定性值。需要注意的是，之前的研究 [19,13] 将不确定性用于组合重叠的边界框或识别不太确定的对象，而我们则从完全不同的角度利用不确定性。也就是说，我们建议通过有向图结构将知识从确定对象转移到不确定对象，从而完善不确定对象的表征，这可能会纠正最初对不确定度较高的对象的错误分类。
